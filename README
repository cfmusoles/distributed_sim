# Distributed SNN simulation

This repository contains code associated with the paper submitted to Frontiers in Neuroinformatics titled "Communication sparsity in distributed Spiking Neural Network Simulations to improve scalability" (approval pending). It consists of a simple SNN timestepped simulator and the implementation of two SNN models: 1) Cortical Microcircuit (reference), and 2) Macaque Visual Cortex (reference). 

Both models are implemented in C++, where different neuron allocation and communication strategies are evaluated. The main features of the implementation are:

	* Time-step driven simulation.
	* Single neuron (leak integrate and fire) and synaptic models (exponential). 
	* Distributed across computing nodes (processes). Within a process, computation is performed sequentially (computation performance is out of the scope of this work).
	* MPI library used for interprocess communication.

These features are built to be representative of the wider class of SNN simulators, with functionally equivalent output (network activity) for the same model execution. Thus, the findings on this work could inform development in other time-step, distributed SNN simulators (such as NEST, NEURON, Arbor).

Profiling timing is done internally wrapping specific functions with MPI_Wtime calls. We are mainly interested in measuring time spent in computation, in implicit synchronisation and in data exchange, as well as how these impact overall performance.

	* Computation: includes the sequential computation of neuron and synapse state updates, as well as effecting the received spiking information from other processes to local neurons.
	* Implicit synchronisation: to quantify load balance, a global artificial barrier is introduced at the end of the computation cycle to measure waiting time on each process\footnote{This is implemented with MPI\_Barrier calls. Although there are limitations to this approach (a process is only held until it is notify that all other processes have entered the barrier; but message propagation delays may result in additional imbalance) it is a good approximation of time to synchronise.}. 
	* Data exchange: measurement of the time it takes for the selected communication pattern to initiate and complete spike propagation.
	* Simulation time: overall global time to complete the simulation, including computation, implicit synchronisation and data exchange.


## Details

Results files from experiments in paper stored in results/archer and results/azure
Python scripts to generate the figures in paper in plots/
Implementation of communication algorithms in paper
	* PEX --> include/PEXCommunicator.h
	* NBX --> include/NBXCommunicator.h
Implementation of workload distribution algorithms
	* Random Balanced --> include/RandomBalancedPartitioning.h
	* Round Robin --> include/RoundRobinPartitioning.h
	* Hypergraph partitioning --> include/HypergraphPartitioning.h
- Description of main files
	* src/distSim.cpp --> simulator code, model builder


## Instructions on how to run

### Dependencies (metis, parmetis, zoltan, MPI compiler)
	metis 5.1 http://glaros.dtc.umn.edu/gkhome/metis/metis/download
	parmetis 4.0.3 http://glaros.dtc.umn.edu/gkhome/metis/parmetis/download
	zoltan 3.83http://www.cs.sandia.gov/Zoltan/Zoltan_download.html
	OpenMPI 3.0.0 or MPI Intel 5.X
	C++11 minimum
### Compilation (modify Makefile to match libraries installation)
	METIS_PATH
	PARMETIS_PATH
	ZOLTAN_PATH
### Running. Parameters
	* `-n`: test name
	* `-c`: communication pattern ('pex' or 'nbx')
	* `-p`: workload distribution (partitioning of neurons) ('randomBalanced','roundrobin' or 'hypergraphPartitioning')
	* `-s`: random seed
	* `-w`: neuronal activity file 
	* `-k`: 0 to 1000 (1000 = 100%) fraction of synapses (scaling model)
	* `-f`: 0 to 1000 (1000 = 100%) fraction of neurons (scaling model)
	* `-t`: simulated time in ms
	* `-m`: model selection ('cm' or 'mcv')




*** DISTRIBUTED SIMULATOR ***

Compiling instructions:

In order to run the code, you must compile it issuing the command:

make

Which will generate the distSim executable in Linux. To compile it, you must have the library METIS installed and configured in your system (ParMETIS and SCALASCA are optional and should not be a problem if you do not have them. METIS is quite simple to install and configure, see:

Download: http://glaros.dtc.umn.edu/gkhome/metis/metis/download
Manual: http://glaros.dtc.umn.edu/gkhome/fetch/sw/metis/manual.pdf

Note that the makefile expects METIS to be installed in the following folder: $(HOME)/metis_build. If you choose to have it elsewhere, please modify the Makefile to point towards the correct folder.

Running instructions:

To run the simulation, issue the following command from the project folder:

mpirun -np XX distSim test_name comm_pattern partitioning

Where XX is the number of processes you want to use, and the parameters after distSim can be specified as follows:

* test_name: name of the filename that contains simulation results (including sim time, sync time, etc.).
* comm_pattern: option to specify the MPI communication strategy to be used. The options are: allGather (to use MPI_AllGatherv to send messages between processes), p2p (to use the point-2-point with master node coordination) and subscriber (to use the point-2-point with preloaded sender lists). See the PDF attached for more info on each of the strategies.
* partitioning: specify whether to use graph partitioning to distribute workload (using graphPartitioning) or random allocation (using random).
